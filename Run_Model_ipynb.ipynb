{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BurgundyIsAPublicEnemy/EPIDEMIUM-Season-3/blob/main/Run_Model_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and create a submission model\n",
        "Set up your variables below (make sure they point to the right place) and hit run. Let the model do it's thing\n",
        "\n",
        "Remember to use a GPU Runtime!"
      ],
      "metadata": {
        "id": "2tDJuT5N9rz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install colab-env --upgrade\n",
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21TvlQb9dUKF",
        "outputId": "7a43e3c9-ba42-48b5-8bd2-efdf9559d2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.19.2\n",
            "Collecting colab-env\n",
            "  Downloading colab-env-0.2.0.tar.gz (4.7 kB)\n",
            "Requirement already satisfied: python-dotenv<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from colab-env) (0.19.2)\n",
            "Building wheels for collected packages: colab-env\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-env: filename=colab_env-0.2.0-py3-none-any.whl size=3838 sha256=6d0c76a627a6a5a824e951313ad0f6e2fb3749be26a2c3d1d7dfb4bc142e0d19\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/ca/e8/3d25b6abb4ac719ecb9e837bb75f2a9b980430005fb12a9107\n",
            "Successfully built colab-env\n",
            "Installing collected packages: colab-env\n",
            "Successfully installed colab-env-0.2.0\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.5.8-py3-none-any.whl (526 kB)\n",
            "\u001b[K     |████████████████████████████████| 526 kB 9.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 75.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.43.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 75.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.10)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 77.3 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=83277b08933d42ac105c88c51fa6326f57a83c021df228912dfe4c0b2ab234a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, torchmetrics, PyYAML, pyDeprecate, future, pytorch-lightning\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2022.1.0 future-0.18.2 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.8 torchmetrics-0.6.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzr_mPBjol6H",
        "outputId": "a360428e-d028-4300-8e56-bf1490e58459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "\n",
        "colab_env.__version__"
      ],
      "metadata": {
        "id": "tferRKz0a4I8",
        "outputId": "e12582bf-33d6-44ab-9a07-51063fdc9960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Python-dotenv could not parse statement starting at line 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.2.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!more /content/gdrive/MyDrive/vars.env"
      ],
      "metadata": {
        "id": "hUo90-9Va5uy",
        "outputId": "81794ae9-dff1-4ad3-c7b5-66cc896d353f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGEFILES = 'WHERE YOUR DATAIKU IMAGES ARE LOCATED'\n",
            "TABULARTRAINING = 'WHERE THE TRAINNG CSV IS AT'\n",
            "TABULARTEST = 'WHERE THE TEST CSV IS AT '\n",
            "FULLSTACKTRAIN = 'WHERE YOUR TIFS ARE'\n",
            "TRAIN_AUGMENTED_PATH = 'WHERE YOU WANT TO PUT YOUR NEW TRAINING CSV'\n",
            "TEST_AUGMENTED_PATH = 'WHERE YOU WANT TO PUT YOUR NEW TEST CSV'\n",
            "METADATA_PATH = 'THE PARENT FOLDER FOR TRAIN_AUGMENTED_PATH AND TEST_AUGMENTED_P\n",
            "ATH - ENDS WITH A /\n",
            "TENPERCENT_MODEL_PATH = 'WHERE TEN PERCENT IS STORED'\n",
            "IMG_TO_ANALYZE = 'WHAT IMAGE YOU WANT TO RUN VISUALIZATIONS ON'\n",
            "FOLDER_TO_OUTPUT = 'THE FOLDER YOU WANT TO TO STORE YOUR IMAGE IN'\n",
            "MODEL_PATH = 'OUTPUT YOUR TRAINED MODELS'\n",
            "patience = 'How long you want to be patient before early stopping'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TEN_PERCENT_MODEL_PATH = os.getenv(\"TENPERCENT_MODEL_PATH\")\n",
        "patience = os.getenv(\"patience\")\n",
        "WORKSPACE_PATH = os.getenv(\"WORKSPACE_PATH\")\n",
        "\n",
        "MODEL_PATH = os.getenv(\"MODEL_PATH\")"
      ],
      "metadata": {
        "id": "930wMEVXa7bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(patience)"
      ],
      "metadata": {
        "id": "HUkJihMDbECc",
        "outputId": "6d766ba8-6cc7-4d66-e905-79b1a5da81a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How long you want to be patient before early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmAQrHrWGOOw"
      },
      "outputs": [],
      "source": [
        "# Config Class\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.FOLDS = 5\n",
        "        self.EPOCHS = 30\n",
        "        self.DEVICE = 'cuda'\n",
        "        self.TRAIN_BS = 16\n",
        "        self.VALID_BS = 8\n",
        "        self.loss_fn = nn.L1Loss()\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7cUNdqGpful",
        "outputId": "3912d956-f5d3-48e9-949e-15a743e5cff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.5.8)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2021.11.1)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.6.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.9)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzNspleLloxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os \n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import Adam\n",
        "from torch.nn import L1Loss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "Path.ls = lambda x: list(x.iterdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr4upWXzspzn",
        "outputId": "d0727ac9-f4ec-446e-d202-84b3b17c5e8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/Train'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/Test'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/train_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/train_minus_hold_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/holdout_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/test_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/.ipynb_checkpoints')]"
            ]
          },
          "metadata": {},
          "execution_count": 577
        }
      ],
      "source": [
        "path = Path(WORKSPACE_PATH)\n",
        "path.ls()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_LkgltabU4F"
      },
      "source": [
        "## Data Prep & Loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bHRgSV5Ru6Q"
      },
      "outputs": [],
      "source": [
        "# get train \n",
        "train_df = pd.read_csv(str(path.ls()[2]))\n",
        "test_df = pd.read_csv(str(path.ls()[5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfHgno21LdDd",
        "outputId": "aef0a35d-b079-42df-c38e-244bebefe4bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 579
        }
      ],
      "source": [
        "# unique patinet ids \n",
        "unique_patient_ids = train_df.id.unique()\n",
        "len(unique_patient_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR3ehpHueV7k",
        "outputId": "3035a7ec-bd81-44e8-9145-0cd1bd57b1bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['afdc1c', 'b3c9bb', 'b41668', 'a4fa68', 'b1abe7', 'adc0ca',\n",
              "       'b32f11', 'af8dca', 'aba442', 'b293e2', 'b02926', 'b110d5',\n",
              "       'abf1b4', 'b4b14e', 'ab55eb', 'ad7219', 'b4fddb', 'b5e396',\n",
              "       'a801cb', 'b1fa79', 'a8ebaf', 'b59738', 'aa21da', 'b6cb24',\n",
              "       'ae5b78', 'b075a7', 'af4155', 'acd8f0', 'a54803', 'a4ad44',\n",
              "       'a85076', 'aa6e3d', 'a6cafe', 'a89f20', 'b67e5a', 'a93ad8',\n",
              "       'aea82d', 'a67dfe', 'a5969b', 'b2e232', 'b0c41b', 'b24726'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 580
        }
      ],
      "source": [
        "unique_patient_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov0RvLUblaUo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLSTcaCIpPF-",
        "outputId": "aeb71999-21f0-4e13-ca2e-f0591e0ddd78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'usage', 'image_file', 'image_rename', 'current_directory',\n",
              "       'layer', 'img_type', 'OMS', 'sexe (0=F 1=M)', 'DDN', 'Date biopsie',\n",
              "       'Age au diag', 'Deces Code', 'Code recidive', 'localisation',\n",
              "       'RNAscope', 'T', 'N', 'M', 'Tabac', 'Alcool', 'Data', 'OS',\n",
              "       'id_encoding', 'image_rename_encoding'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 581
        }
      ],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdLLb4YGpB7C"
      },
      "outputs": [],
      "source": [
        "train_cols_to_drop = ['id' , 'usage' ,'image_file' ,'image_rename' ,'current_directory' ,'layer' ,'img_type' ,'N' ,'Data' ,'id_encoding' ,'image_rename_encoding', 'OS', 'DDN', 'Date biopsie']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8c3IQb3U3TQ"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, path, df, folder = 'Train', is_train = 1):\n",
        "      \"\"\"Summary or Description of the Function\n",
        "      \n",
        "      Parameters:\n",
        "      path (Path): path of drive folder that contains csvs and train / test image folders \n",
        "      df (Pandas df )  : sub fold dataframe for fold patients \n",
        "      folder (str) : train or test folder \n",
        "      \n",
        "      Returns:\n",
        "      img , tab and target \n",
        "      \n",
        "      \"\"\"\n",
        "\n",
        "      self.df = df\n",
        "      self.folder = folder\n",
        "      self.path = path \n",
        "      self.is_train = is_train\n",
        "      \n",
        "      self.train_transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=45),\n",
        "                transforms.ToTensor()\n",
        "                ])\n",
        "        \n",
        "      self.test_transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor()])\n",
        "      \n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "      row = self.df.loc[idx,:]\n",
        "      pid = row['id']\n",
        "      sub_df = self.df[self.df['id'] == pid]\n",
        "        \n",
        "      try: \n",
        "     \n",
        "        img_id = np.random.choice(len(sub_df)) # randomly choose a patient image inside the fold \n",
        "        image = cv2.imread(str(self.path)  + '/' + self.folder + '/' + sub_df.iloc[img_id,:]['image_rename'])\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        img = self.train_transform(image) if self.is_train else self.test_transform(image)\n",
        "         \n",
        "        tab = torch.from_numpy(sub_df.iloc[img_id,:].drop(train_cols_to_drop).values.astype(np.float)).float() # dtype = torch.float32\n",
        "        target = torch.tensor(row['OS'])\n",
        "        return (img,tab), target , torch.tensor(sub_df.iloc[img_id]['id_encoding']) , torch.tensor(sub_df.iloc[img_id]['image_rename_encoding'])\n",
        "        \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(pid, img_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRWfmtmaTgvl"
      },
      "source": [
        "## Collate Function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HziZdEn_TirM"
      },
      "outputs": [],
      "source": [
        "def collate_fn(b):\n",
        "    xs, ys, pids,img_rename = zip(*b)\n",
        "    imgs, tabs = zip(*xs) # doule tuple \n",
        "    return (torch.stack(imgs).float(),torch.stack(tabs).float()),torch.stack(ys).float() , torch.stack(pids) , torch.stack(img_rename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSRPze0cVpAv"
      },
      "source": [
        "## Generating Splits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k148qJu2VrwO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def get_split_idxs(n_folds=5):\n",
        "    kv = KFold(n_splits=n_folds)\n",
        "    splits = []\n",
        "    for i,(train_idx, valid_idx) in enumerate(kv.split(unique_patient_ids)):\n",
        "        splits.append((train_idx, valid_idx))\n",
        "        \n",
        "    return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBpu-Ow8Vtvm"
      },
      "outputs": [],
      "source": [
        "splits = get_split_idxs(n_folds=config.FOLDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ4pjbDFV1lE",
        "outputId": "4db2dc2c-96e2-40fb-fe44-e966fd681ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "         26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([0, 1, 2, 3, 4, 5, 6, 7, 8])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "         26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([ 9, 10, 11, 12, 13, 14, 15, 16, 17])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([18, 19, 20, 21, 22, 23, 24, 25])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([26, 27, 28, 29, 30, 31, 32, 33])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
              "  array([34, 35, 36, 37, 38, 39, 40, 41]))]"
            ]
          },
          "metadata": {},
          "execution_count": 587
        }
      ],
      "source": [
        "splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo-olt8sQ2Tj"
      },
      "source": [
        "# Training propsed model\n",
        "\n",
        "GOAL:\n",
        "```\n",
        "Image Data --> CNNLayer \n",
        "                    \\\n",
        "                     ---> FCLayer ---> Output\n",
        "                    /\n",
        "Metadata --> FCLayer\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80E89X4BT6Lv"
      },
      "source": [
        "## Loading Supervised Pretrained \n",
        "\n",
        "Original paper: https://arxiv.org/pdf/2011.13971.pdf\n",
        "\n",
        "Repo: https://github.com/ozanciga/self-supervised-histopathology/tree/tenpercent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY5FUluLeN6i"
      },
      "outputs": [],
      "source": [
        "RETURN_PREACTIVATION = True  # return features from the model, if false return classification logits\n",
        "NUM_CLASSES = 1  # only used if RETURN_PREACTIVATION = False\n",
        "\n",
        "\n",
        "def load_model_weights(model, weights):\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "    weights = {k: v for k, v in weights.items() if k in model_dict}\n",
        "    if weights == {}:\n",
        "        print('No weight could be loaded..')\n",
        "    model_dict.update(weights)\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = torchvision.models.__dict__['resnet18'](pretrained=False)\n",
        "state = torch.load(TEN_PERCENT_MODEL_PATH, map_location='cuda:0')\n",
        "\n",
        "state_dict = state['state_dict']\n",
        "for key in list(state_dict.keys()):\n",
        "    state_dict[key.replace('model.', '').replace('resnet.', '')] = state_dict.pop(key)\n",
        "\n",
        "model = load_model_weights(model, state_dict)\n",
        "\n",
        "if RETURN_PREACTIVATION:\n",
        "    model.fc = torch.nn.Sequential()\n",
        "else:\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "images = torch.rand((10, 3, 224, 224), device='cuda')\n",
        "\n",
        "out = model(images)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    # Replace the last fully-connected layer\n",
        "    # Parameters of newly constructed modules have requires_grad=True by default\n",
        "    \n",
        "    model.fc = torch.nn.Linear(512, 256,bias = True) \n",
        "    model = model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_lV19Ecep-y"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "proposed_model = copy.deepcopy(model)\n",
        "\n",
        "count = 1\n",
        "for param in proposed_model.parameters():\n",
        "  count += 1\n",
        "\n",
        "cur = 1\n",
        "for param in proposed_model.parameters():\n",
        "  if (cur > (0.8 * count)): \n",
        "    param.requires_grad = True\n",
        "  cur += 1\n",
        "\n",
        "proposed_model = proposed_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxMZaNLnT_nX"
      },
      "source": [
        "## Training Global Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRctuPvUaGKF"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, dl, opt , device, loss_fn):\n",
        "    model.train()\n",
        "    final_loss = []\n",
        "    for X,y,_,_ in dl:\n",
        "        imgs = X[0].to(device)\n",
        "        tabs = X[1].to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(imgs, tabs)\n",
        "        loss = loss_fn(outputs.squeeze(), y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        final_loss.append(loss.detach().cpu().numpy())\n",
        "        #print('Training Example preds vs targets: ::\\t \\n' , outputs , '\\n' , y)\n",
        "    return np.array(final_loss).mean()\n",
        "    \n",
        "def eval_loop(model, dl, device, loss_fn):\n",
        "    model.eval()\n",
        "    final_outputs = []\n",
        "    final_loss = []\n",
        "    with torch.no_grad():\n",
        "        for X,y,_,_ in dl:\n",
        "            imgs = X[0].to(device)\n",
        "            tabs = X[1].to(device)\n",
        "            y=y.to(device)\n",
        "\n",
        "            outputs = model(imgs, tabs)\n",
        "            loss = loss_fn(outputs.squeeze(), y)\n",
        "\n",
        "            final_outputs.extend(outputs.detach().cpu().numpy().tolist())\n",
        "            final_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    print('validation Example preds vs targets: ::\\t \\n' , outputs , '\\n' , y)\n",
        "    return final_outputs, final_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXqjrWURRMrc"
      },
      "outputs": [],
      "source": [
        "class Global_Model(nn.Module): # model to combina both tab and imag \n",
        "    def __init__(self , pretrained_medical_resnet):\n",
        "        super().__init__()\n",
        "        self.conv_model = pretrained_medical_resnet # after freezing some layers and setting regression node as 1 not 4 \n",
        "        self.tab_model = nn.Sequential(nn.Linear(11, 500),\n",
        "                                  nn.BatchNorm1d(500),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2),\n",
        "                                  nn.Linear(500,250),\n",
        "                                  nn.BatchNorm1d(250),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2))\n",
        "                                  \n",
        "        self.output =             nn.Sequential(\n",
        "                                                nn.Linear(250 + 256 ,250),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(250, 125),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(125, 60),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(60, 20),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(20, 1, bias = True ))\n",
        "    def forward(self, x,tab): # x image , tab is tabular data related \n",
        "        x = self.conv_model(x)\n",
        "        tab_out = self.tab_model(tab)\n",
        "        x = torch.cat([x, tab_out],dim=1)\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcHaW7FYaV2l"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "for i in range(config.FOLDS):\n",
        "    models[i] = copy.deepcopy(Global_Model(copy.deepcopy(proposed_model)))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5y9erznawDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fed2886-1227-4ef8-88c8-2fea97c7671d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================Fold : 0 ================\n",
            "train_idx :  [ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32\n",
            " 33 34 35 36 37 38 39 40 41] \n",
            " valid_idx [0 1 2 3 4 5 6 7 8]\n",
            "=================EPOCHS 1================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[76.8456],\n",
            "        [89.6034],\n",
            "        [85.3866],\n",
            "        [82.5891],\n",
            "        [80.5516],\n",
            "        [82.3028],\n",
            "        [79.0252],\n",
            "        [82.4473]], device='cuda:0') \n",
            " tensor([13., 65., 46., 70., 65., 70., 65., 13.], device='cuda:0')\n",
            "New best model! Score:  34.790237\n",
            "Train Loss:: \t 35.672806\n",
            "Validation Loss ::\t 34.790237\n",
            "=================EPOCHS 2================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[18.1101],\n",
            "        [18.6076],\n",
            "        [19.6700],\n",
            "        [51.4613],\n",
            "        [13.9629],\n",
            "        [20.4325],\n",
            "        [47.7119],\n",
            "        [15.5563]], device='cuda:0') \n",
            " tensor([13., 46., 47., 70., 13., 47., 72., 13.], device='cuda:0')\n",
            "New best model! Score:  19.372866\n",
            "Train Loss:: \t 17.397226\n",
            "Validation Loss ::\t 19.372866\n",
            "=================EPOCHS 3================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[28.6906],\n",
            "        [82.6457],\n",
            "        [27.5403],\n",
            "        [70.4448],\n",
            "        [49.2933],\n",
            "        [24.7752],\n",
            "        [23.2063],\n",
            "        [58.5128]], device='cuda:0') \n",
            " tensor([46., 65., 47., 72., 43., 13., 47., 70.], device='cuda:0')\n",
            "New best model! Score:  9.523935\n",
            "Train Loss:: \t 15.855124\n",
            "Validation Loss ::\t 9.523935\n",
            "=================EPOCHS 4================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[61.6618],\n",
            "        [44.9935],\n",
            "        [13.4736],\n",
            "        [46.1266],\n",
            "        [14.4924],\n",
            "        [14.9346],\n",
            "        [37.2285],\n",
            "        [54.6529]], device='cuda:0') \n",
            " tensor([65., 43., 13., 72., 13., 13., 46., 70.], device='cuda:0')\n",
            "New best model! Score:  9.108723\n",
            "Train Loss:: \t 14.595711\n",
            "Validation Loss ::\t 9.108723\n",
            "=================EPOCHS 5================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[21.5572],\n",
            "        [49.0430],\n",
            "        [47.1056],\n",
            "        [ 8.1956],\n",
            "        [35.2843],\n",
            "        [35.2505],\n",
            "        [49.4034],\n",
            "        [35.0377]], device='cuda:0') \n",
            " tensor([47., 65., 70., 13., 43., 43., 65., 43.], device='cuda:0')\n",
            "BAD! Patience counter :  1\n",
            "Train Loss:: \t 15.18627\n",
            "Validation Loss ::\t 15.866109\n",
            "=================EPOCHS 6================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[10.0787],\n",
            "        [52.2204],\n",
            "        [36.0384],\n",
            "        [55.2628],\n",
            "        [28.6453],\n",
            "        [51.5797],\n",
            "        [ 7.7033],\n",
            "        [52.9656]], device='cuda:0') \n",
            " tensor([13., 70., 65., 70., 47., 72., 13., 70.], device='cuda:0')\n",
            "BAD! Patience counter :  2\n",
            "Train Loss:: \t 14.620448\n",
            "Validation Loss ::\t 14.888833\n",
            "=================EPOCHS 7================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[12.3785],\n",
            "        [71.6062],\n",
            "        [10.6153],\n",
            "        [34.9349],\n",
            "        [64.9543],\n",
            "        [73.2824],\n",
            "        [43.8336],\n",
            "        [10.3094]], device='cuda:0') \n",
            " tensor([13., 65., 13., 46., 70., 65., 43., 13.], device='cuda:0')\n",
            "New best model! Score:  6.8968406\n",
            "Train Loss:: \t 14.069011\n",
            "Validation Loss ::\t 6.8968406\n",
            "=================EPOCHS 8================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[31.1890],\n",
            "        [71.9000],\n",
            "        [32.3073],\n",
            "        [64.8023],\n",
            "        [63.9053],\n",
            "        [31.0299],\n",
            "        [72.4415],\n",
            "        [32.4938]], device='cuda:0') \n",
            " tensor([46., 70., 43., 70., 70., 47., 70., 46.], device='cuda:0')\n",
            "BAD! Patience counter :  1\n",
            "Train Loss:: \t 13.56422\n",
            "Validation Loss ::\t 7.7202277\n",
            "=================EPOCHS 9================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[48.9335],\n",
            "        [ 9.2254],\n",
            "        [35.6431],\n",
            "        [26.9340],\n",
            "        [ 7.9903],\n",
            "        [28.4286],\n",
            "        [59.2670],\n",
            "        [ 7.0364]], device='cuda:0') \n",
            " tensor([72., 13., 43., 46., 13., 47., 70., 13.], device='cuda:0')\n",
            "BAD! Patience counter :  2\n",
            "Train Loss:: \t 14.40227\n",
            "Validation Loss ::\t 12.226694\n",
            "=================EPOCHS 10================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[55.2087],\n",
            "        [20.0236],\n",
            "        [46.7450],\n",
            "        [19.5448],\n",
            "        [56.1952],\n",
            "        [ 9.0234],\n",
            "        [57.8606],\n",
            "        [ 8.2314]], device='cuda:0') \n",
            " tensor([72., 46., 65., 47., 72., 13., 72., 13.], device='cuda:0')\n",
            "BAD! Patience counter :  3\n",
            "Train Loss:: \t 13.895354\n",
            "Validation Loss ::\t 16.347116\n",
            "=================EPOCHS 11================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[ 9.4078],\n",
            "        [52.2104],\n",
            "        [ 8.3132],\n",
            "        [24.9635],\n",
            "        [30.2432],\n",
            "        [ 9.3072],\n",
            "        [55.0185],\n",
            "        [49.6787]], device='cuda:0') \n",
            " tensor([13., 72., 13., 47., 43., 13., 65., 70.], device='cuda:0')\n",
            "BAD! Patience counter :  4\n",
            "Train Loss:: \t 14.220006\n",
            "Validation Loss ::\t 13.706143\n",
            "=================EPOCHS 12================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[28.1292],\n",
            "        [40.1490],\n",
            "        [30.4147],\n",
            "        [50.6101],\n",
            "        [36.8168],\n",
            "        [29.1176],\n",
            "        [10.1184],\n",
            "        [28.7490]], device='cuda:0') \n",
            " tensor([47., 43., 46., 72., 43., 47., 13., 46.], device='cuda:0')\n",
            "BAD! Patience counter :  5\n",
            "Early stopping saved\n",
            "===================Fold : 1 ================\n",
            "train_idx :  [ 0  1  2  3  4  5  6  7  8 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32\n",
            " 33 34 35 36 37 38 39 40 41] \n",
            " valid_idx [ 9 10 11 12 13 14 15 16 17]\n",
            "=================EPOCHS 1================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[52.3778],\n",
            "        [55.6807],\n",
            "        [56.3671],\n",
            "        [48.4290],\n",
            "        [47.4953],\n",
            "        [47.1373],\n",
            "        [52.6019],\n",
            "        [50.1667]], device='cuda:0') \n",
            " tensor([31., 66., 10., 59., 31., 84., 21., 31.], device='cuda:0')\n",
            "New best model! Score:  23.352295\n",
            "Train Loss:: \t 32.80968\n",
            "Validation Loss ::\t 23.352295\n",
            "=================EPOCHS 2================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[44.2785],\n",
            "        [42.5006],\n",
            "        [32.6713],\n",
            "        [43.4281],\n",
            "        [52.9543],\n",
            "        [36.1441],\n",
            "        [52.0390],\n",
            "        [51.4937]], device='cuda:0') \n",
            " tensor([21., 21., 21., 21., 84., 21., 66., 66.], device='cuda:0')\n",
            "New best model! Score:  18.117474\n",
            "Train Loss:: \t 18.162712\n",
            "Validation Loss ::\t 18.117474\n",
            "=================EPOCHS 3================\n",
            "validation Example preds vs targets: ::\t \n",
            " tensor([[31.3905],\n",
            "        [33.0559],\n",
            "        [56.7883],\n",
            "        [31.8363],\n",
            "        [68.1816],\n",
            "        [31.8597],\n",
            "        [72.6427],\n",
            "        [29.0279]], device='cuda:0') \n",
            " tensor([21., 12., 59., 12., 84., 21., 84., 21.], device='cuda:0')\n",
            "New best model! Score:  10.775967\n",
            "Train Loss:: \t 15.690427\n",
            "Validation Loss ::\t 10.775967\n",
            "=================EPOCHS 4================\n"
          ]
        }
      ],
      "source": [
        "history = []\n",
        "trainhistory = []\n",
        "\n",
        "bestModels = []\n",
        "bestScores = []\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):\n",
        "    bestModel = None\n",
        "    bestHistory = 100\n",
        "\n",
        "    print(f\"===================Fold : {i} ================\")\n",
        "    print(\"train_idx : \" , train_idx , \"\\n valid_idx\" , valid_idx)\n",
        "\n",
        "    train = train_df.loc[train_df['id'].isin(unique_patient_ids[train_idx])].reset_index(drop=True)\n",
        "    valid = train_df.loc[train_df['id'].isin(unique_patient_ids[valid_idx])].reset_index(drop=True)\n",
        "    \n",
        "    train_ds = Dataset(path, train,'Train' ,1)\n",
        "    train_dl = torch.utils.data.DataLoader(dataset=train_ds,batch_size=config.TRAIN_BS,shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "    valid_ds = Dataset(path, valid,'Train' ,0)\n",
        "    valid_dl = torch.utils.data.DataLoader(dataset=valid_ds,batch_size=config.VALID_BS, shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "    model = models[i]\n",
        "    model.to(config.DEVICE)\n",
        "    lr=1e-3\n",
        "    momentum = 0.9\n",
        "    \n",
        "    num_steps = len(train_dl)\n",
        "    optimizer = Adam(model.parameters(), lr=lr,weight_decay=0.01)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"=================EPOCHS {epoch+1}================\")\n",
        "        train_loss = train_loop(model, train_dl, optimizer, config.DEVICE,config.loss_fn)\n",
        "        metrics = eval_loop(model, valid_dl, config.DEVICE,config.loss_fn)\n",
        "        total_loss = np.array(metrics[1]).mean()\n",
        "\n",
        "        if (total_loss < bestHistory):\n",
        "          print('New best model! Score: ', total_loss)\n",
        "          patienceCounter = 0\n",
        "          bestHistory = total_loss\n",
        "          bestModel = copy.deepcopy(model)\n",
        "        \n",
        "        if (epoch > patienceCounter):\n",
        "          if (total_loss >  bestHistory):\n",
        "            patienceCounter += 1\n",
        "            print('BAD! Patience counter : ', patienceCounter)\n",
        "\n",
        "        \n",
        "        if (patienceCounter >= patience):\n",
        "          print('Early stopping saved')\n",
        "          break\n",
        "        \n",
        "        losses.append(total_loss)\n",
        "        train_losses.append(train_loss)\n",
        "        print('Train Loss:: \\t', train_loss)\n",
        "        print(\"Validation Loss ::\\t\", total_loss)\n",
        "        \n",
        "    model.to('cpu')\n",
        "\n",
        "    history.append(losses)\n",
        "    bestModels.append(bestModel)\n",
        "    bestScores.append(bestHistory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model utils like graphs and saving"
      ],
      "metadata": {
        "id": "6MGLeF18CDE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure(figsize=(6, 8), dpi=80)\n",
        "\n",
        "f, axes = plt.subplots(len(history), 1)\n",
        "f.set_size_inches(12, 20)\n",
        "for i in range(len(history)):\n",
        "  axes[i].plot(history[i])\n",
        "  #axes[i].plot(trainhistory[i])\n",
        "\n",
        "  axes[i].legend(['Validation Loss'])\n",
        "  axes[i].set_title(' Fold ' + str(i))"
      ],
      "metadata": {
        "id": "FxSv8jP5CH-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best val loss scores per fold\n",
        "for m in history:\n",
        "  print(min(m))"
      ],
      "metadata": {
        "id": "1NK6giFLCgd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best models\n",
        "c = 0\n",
        "for m in bestModels:\n",
        "    torch.save(m.state_dict(), MODEL_PATH + f'/tab_best_fold_{c}.pth')\n",
        "    c += 1"
      ],
      "metadata": {
        "id": "fVQ3kzQVjHaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, m in models.items():\n",
        "    torch.save(m.state_dict(), MODEL_PATH + f'/fold_{k}.pth')"
      ],
      "metadata": {
        "id": "_csLQKqzCNdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OriidIi3coKP"
      },
      "source": [
        "# Testing Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBtFOYqyDWsV"
      },
      "outputs": [],
      "source": [
        "fold_models_directory = Path(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_models_directory.ls()[6:11]"
      ],
      "metadata": {
        "id": "UtknJHZyTQ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPiYeptIDTE3"
      },
      "outputs": [],
      "source": [
        "model_device = torch.device('cpu')\n",
        "for i , fold_model_path in enumerate(fold_models_directory.ls()[6:11]) :\n",
        "    models[i].load_state_dict(torch.load(str(fold_model_path) , map_location = model_device), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojBhpb88IpEQ"
      },
      "outputs": [],
      "source": [
        "test_df['OS'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ny534iiFgn_"
      },
      "outputs": [],
      "source": [
        "test_pred_dict = {}\n",
        "submissionDF = pd.DataFrame()\n",
        "\n",
        "test_ds = Dataset(path, test_df,'Test' ,0)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds,batch_size=1, shuffle=False,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dic = {k:v for k,v in dict(tuple(test_df[['id' ,'id_encoding']].groupby(['id','id_encoding']))).keys()}\n",
        "decoding_dic = {v:k for k,v in encoding_dic.items()} "
      ],
      "metadata": {
        "id": "_23R0wHvlrZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_count_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9).flatten())) # count number of occurence for a cetain patient id in the batch \n",
        "fold_mean_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9,dtype=int).flatten())) # compute mean fold "
      ],
      "metadata": {
        "id": "6BWpmpTQWcKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df = pd.DataFrame(columns = fold_mean_dict.keys()) "
      ],
      "metadata": {
        "id": "qVUuYAg_ekqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydbgwziRtgcb"
      },
      "outputs": [],
      "source": [
        "# Test Set \n",
        "for key , fold_model in models.items() : \n",
        "  print(f\"=================Predictions of fold Model {key}================\")\n",
        "  fold_model.to(config.DEVICE)\n",
        "  fold_model.eval()\n",
        "  with torch.no_grad():\n",
        "      for X,y,pid,_ in test_dl:\n",
        "          imgs = X[0].to(config.DEVICE)\n",
        "          tabs = X[1].to(config.DEVICE)\n",
        "          y=y.to(config.DEVICE)\n",
        "          patient_id = pid.detach().cpu().numpy()[0]\n",
        "          outputs = fold_model(imgs, tabs).detach().cpu().numpy()[0]\n",
        "\n",
        "          fold_count_dict[decoding_dic[patient_id]]+=1\n",
        "          fold_mean_dict[decoding_dic[patient_id]] += outputs\n",
        "           \n",
        "      fold_mean_dict = {k : v / fold_count_dict[k]  for k,v in fold_mean_dict.items()}\n",
        "      print (\"Fold count dict : \" , fold_count_dict)\n",
        "      print (\"Fold mean dict after dividing : \" , fold_mean_dict)\n",
        "    \n",
        "      final_submit_df.loc[len(final_submit_df)] = [v[0] for v in fold_mean_dict.values()]\n",
        "      fold_mean_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9,dtype=int).flatten())) # reset for next fold \n",
        "      fold_count_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9).flatten()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df"
      ],
      "metadata": {
        "id": "Qgt0aSPdg539"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df.mean(axis=0)"
      ],
      "metadata": {
        "id": "AdB_4gMyiMfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df.std(axis=0)"
      ],
      "metadata": {
        "id": "7mC5Ka4xiPUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissionDF = pd.DataFrame(final_submit_df.mean(axis=0)).reset_index().rename({'index' : 'id' , 0 : 'prediction' } , axis=1 )"
      ],
      "metadata": {
        "id": "DjDshyx6ieVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissionDF"
      ],
      "metadata": {
        "id": "LcLGHgsEjSVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pabXigZzHkw3"
      },
      "outputs": [],
      "source": [
        "submissionDF.to_csv(\"submission_V1.csv\" , index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Run_Model-ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}