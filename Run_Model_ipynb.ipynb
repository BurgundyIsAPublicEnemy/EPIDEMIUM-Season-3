{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BurgundyIsAPublicEnemy/EPIDEMIUM-Season-3/blob/main/Run_Model_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and create a submission model\n",
        "Set up your variables below (make sure they point to the right place) and hit run. Let the model do it's thing\n",
        "\n",
        "Remember to use a GPU Runtime!"
      ],
      "metadata": {
        "id": "2tDJuT5N9rz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install colab-env --upgrade\n",
        "!pip install pytorch_lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21TvlQb9dUKF",
        "outputId": "e3260a33-9111-44f8-e835-7ad7d2b003c8"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.7/dist-packages (0.19.2)\n",
            "Requirement already satisfied: colab-env in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: python-dotenv<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from colab-env) (0.19.2)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.5.8)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.6.2)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.7.0)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.1.0)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.43.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.10)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (5.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzr_mPBjol6H",
        "outputId": "345c7a3d-5fbb-4d10-83c6-9a1236860c9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import colab_env\n",
        "\n",
        "colab_env.__version__"
      ],
      "metadata": {
        "id": "tferRKz0a4I8",
        "outputId": "dd74916a-d9b7-4348-a570-fb6038cc1e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.2.0'"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!more /content/drive/MyDrive/vars.env"
      ],
      "metadata": {
        "id": "hUo90-9Va5uy",
        "outputId": "7f8e5d00-b2e0-4bf6-e9f5-45d89e745f05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMAGEFILES = '/content/drive/MyDrive/Epidemium Season 3/ORLIAn /image_data_v2'\n",
            "TABULARTRAINING = '/content/drive/MyDrive/Epidemium Season 3/ORLIAn /image_data_\n",
            "v2/avatarsV2_train.csv'\n",
            "TABULARTEST = '/content/drive/MyDrive/Epidemium Season 3/ORLIAn /image_data_v2/a\n",
            "vatarsV2_test_X.csv'\n",
            "FULLSTACKTRAIN = '/content/drive/MyDrive/Epidemium Season 3/ORLIAn /datasets/all\n",
            "_layers_active_png/results'\n",
            "TRAIN_AUGMENTED_PATH = '/content/drive/MyDrive/Kaggle/ORLIA/Train/'\n",
            "TEST_AUGMENTED_PATH = '/content/drive/MyDrive/Kaggle/ORLIA/Test/'\n",
            "METADATA_PATH = '/content/drive/MyDrive/Kaggle/ORLIA'\n",
            "TENPERCENT_MODEL_PATH = '/content/drive/MyDrive/Kaggle/ModelDump/tenpercent_resn\n",
            "et18.ckpt'\n",
            "IMG_TO_ANALYZE = '/content/drive/MyDrive/Epidemium Season 3/ORLIAn /image_data_v\n",
            "2/Cellule inflamatoire 2/a4ad44_[12800,52067]_composite_image.jpg'\n",
            "FOLDER_TO_OUTPUT = './'\n",
            "OUTPUT_MODEL_PATH = '/content/drive/MyDrive/Kaggle/ModelDump/'\n",
            "WORKSPACE_PATH = '/content/drive/MyDrive/Kaggle/ORLIA'\n",
            "MODEL_PATH = '/content/drive/MyDrive/Kaggle/ModelDump/fold_0.pth'\n",
            "patience = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "TEN_PERCENT_MODEL_PATH = os.getenv(\"TENPERCENT_MODEL_PATH\")\n",
        "patience = int(os.getenv(\"patience\"))\n",
        "WORKSPACE_PATH = os.getenv(\"WORKSPACE_PATH\")\n",
        "\n",
        "OUTPUT_MODEL_PATH = os.getenv(\"OUTPUT_MODEL_PATH\")"
      ],
      "metadata": {
        "id": "930wMEVXa7bY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(OUTPUT_MODEL_PATH)"
      ],
      "metadata": {
        "id": "HUkJihMDbECc",
        "outputId": "2ea955d5-624b-4363-e971-2b01c558164f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Kaggle/ModelDump/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "MzNspleLloxS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os \n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import Adam\n",
        "from torch.nn import L1Loss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_\n",
        "\n",
        "from torchvision.io import read_image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "Path.ls = lambda x: list(x.iterdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "hmAQrHrWGOOw"
      },
      "outputs": [],
      "source": [
        "# Config Class\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.FOLDS = 5\n",
        "        self.EPOCHS = 30\n",
        "        self.DEVICE = 'cuda'\n",
        "        self.TRAIN_BS = 16\n",
        "        self.VALID_BS = 8\n",
        "        self.loss_fn = nn.L1Loss()\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr4upWXzspzn",
        "outputId": "f92cae35-3b75-44ba-e477-8244593f9bb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/Test'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/Train'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/train_minus_hold_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/test_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/holdout_img_data.csv'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ORLIA/train_img_data.csv')]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "path = Path(WORKSPACE_PATH)\n",
        "path.ls()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_LkgltabU4F"
      },
      "source": [
        "## Data Prep & Loading "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "4bHRgSV5Ru6Q"
      },
      "outputs": [],
      "source": [
        "# get train \n",
        "train_df = pd.read_csv(str(path.ls()[5]))\n",
        "test_df = pd.read_csv(str(path.ls()[3]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "73dxk-_BA-jQ",
        "outputId": "1083f485-3b28-4bb2-cf46-fe5c4149229c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-466d6b1d-d75b-4197-ab72-a531e5065a4e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>usage</th>\n",
              "      <th>image_file</th>\n",
              "      <th>image_rename</th>\n",
              "      <th>current_directory</th>\n",
              "      <th>layer</th>\n",
              "      <th>img_type</th>\n",
              "      <th>OMS</th>\n",
              "      <th>sexe (0=F 1=M)</th>\n",
              "      <th>DDN</th>\n",
              "      <th>Date biopsie</th>\n",
              "      <th>Age au diag</th>\n",
              "      <th>Deces Code</th>\n",
              "      <th>Code recidive</th>\n",
              "      <th>localisation</th>\n",
              "      <th>RNAscope</th>\n",
              "      <th>T</th>\n",
              "      <th>N</th>\n",
              "      <th>M</th>\n",
              "      <th>Tabac</th>\n",
              "      <th>Alcool</th>\n",
              "      <th>Data</th>\n",
              "      <th>id_encoding</th>\n",
              "      <th>image_rename_encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aabb0e</td>\n",
              "      <td>test</td>\n",
              "      <td>aabb0e_[12238,43627]_composite_image.jpg</td>\n",
              "      <td>raw_Cellule inflamatoire 4_aabb0e_[12238,43627...</td>\n",
              "      <td>/content/drive/MyDrive/Kaggle/ORLIA/Test/</td>\n",
              "      <td>Cellule inflamatoire 4</td>\n",
              "      <td>raw</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>69.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Image + clinical</td>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a7b285</td>\n",
              "      <td>test</td>\n",
              "      <td>a7b285_[13407,58051]_composite_image.jpg</td>\n",
              "      <td>raw_Cellules tumorales et cellules inflammatoi...</td>\n",
              "      <td>/content/drive/MyDrive/Kaggle/ORLIA/Test/</td>\n",
              "      <td>Cellules tumorales et cellules inflammatoires 3</td>\n",
              "      <td>raw</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>76.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Image + clinical</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ac3e32</td>\n",
              "      <td>test</td>\n",
              "      <td>ac3e32_[11938,49725]_composite_image.jpg</td>\n",
              "      <td>raw_Cellules tumorales et cellules inflammatoi...</td>\n",
              "      <td>/content/drive/MyDrive/Kaggle/ORLIA/Test/</td>\n",
              "      <td>Cellules tumorales et cellules inflammatoires 3</td>\n",
              "      <td>raw</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>69.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Image + clinical</td>\n",
              "      <td>2</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b462ff</td>\n",
              "      <td>test</td>\n",
              "      <td>b462ff_[11684,45221]_composite_image.jpg</td>\n",
              "      <td>raw_Cellule inflamatoire 1_b462ff_[11684,45221...</td>\n",
              "      <td>/content/drive/MyDrive/Kaggle/ORLIA/Test/</td>\n",
              "      <td>Cellule inflamatoire 1</td>\n",
              "      <td>raw</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>89.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>78</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Image + clinical</td>\n",
              "      <td>7</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ac8a8b</td>\n",
              "      <td>test</td>\n",
              "      <td>ac8a8b_[16004,54038]_image_with_tissue_seg.jpg</td>\n",
              "      <td>composite_segmentation_tissue_ac8a8b_[16004,54...</td>\n",
              "      <td>/content/drive/MyDrive/Kaggle/ORLIA/Test/</td>\n",
              "      <td>segmentation_tissue</td>\n",
              "      <td>raw</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Image + clinical</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-466d6b1d-d75b-4197-ab72-a531e5065a4e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-466d6b1d-d75b-4197-ab72-a531e5065a4e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-466d6b1d-d75b-4197-ab72-a531e5065a4e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       id usage  ... id_encoding image_rename_encoding\n",
              "0  aabb0e  test  ...           1                   136\n",
              "1  a7b285  test  ...           0                   200\n",
              "2  ac3e32  test  ...           2                   208\n",
              "3  b462ff  test  ...           7                    92\n",
              "4  ac8a8b  test  ...           3                    29\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfHgno21LdDd",
        "outputId": "06bfbfe2-bc10-49c0-f01d-eb44308f021f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "# unique patinet ids \n",
        "unique_patient_ids = train_df.id.unique()\n",
        "len(unique_patient_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR3ehpHueV7k",
        "outputId": "731b56d1-cb76-4d31-ad63-67b785b433c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['a93ad8', 'b110d5', 'b293e2', 'aa21da', 'afdc1c', 'b4b14e',\n",
              "       'b67e5a', 'aba442', 'b4fddb', 'a8ebaf', 'a6cafe', 'a67dfe',\n",
              "       'a54803', 'b0c41b', 'af8dca', 'b5e396', 'aea82d', 'a4fa68',\n",
              "       'b6cb24', 'b1fa79', 'af4155', 'ad7219', 'a801cb', 'acd8f0',\n",
              "       'ae5b78', 'aa6e3d', 'ab55eb', 'b075a7', 'b41668', 'b32f11',\n",
              "       'a89f20', 'abf1b4', 'b02926', 'b1abe7', 'b59738', 'adc0ca',\n",
              "       'b3c9bb', 'b2e232', 'a85076', 'a4ad44', 'a5969b', 'b24726'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ],
      "source": [
        "unique_patient_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov0RvLUblaUo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLSTcaCIpPF-",
        "outputId": "540bfc81-f3b4-45e0-f866-c71427588f4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'usage', 'image_file', 'image_rename', 'current_directory',\n",
              "       'layer', 'img_type', 'OMS', 'sexe (0=F 1=M)', 'DDN', 'Date biopsie',\n",
              "       'Age au diag', 'Deces Code', 'Code recidive', 'localisation',\n",
              "       'RNAscope', 'T', 'N', 'M', 'Tabac', 'Alcool', 'Data', 'OS',\n",
              "       'id_encoding', 'image_rename_encoding'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "train_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "bdLLb4YGpB7C"
      },
      "outputs": [],
      "source": [
        "train_cols_to_drop = ['id' , 'usage' ,'image_file' ,'image_rename' ,'current_directory' ,'layer' ,'img_type' ,'N' ,'Data' ,'id_encoding' ,'image_rename_encoding', 'OS', 'DDN', 'Date biopsie']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "M8c3IQb3U3TQ"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, path, df, folder = 'Train', is_train = 1):\n",
        "      \"\"\"Summary or Description of the Function\n",
        "      \n",
        "      Parameters:\n",
        "      path (Path): path of drive folder that contains csvs and train / test image folders \n",
        "      df (Pandas df )  : sub fold dataframe for fold patients \n",
        "      folder (str) : train or test folder \n",
        "      \n",
        "      Returns:\n",
        "      img , tab and target \n",
        "      \n",
        "      \"\"\"\n",
        "\n",
        "      self.df = df\n",
        "      self.folder = folder\n",
        "      self.path = path \n",
        "      self.is_train = is_train\n",
        "      \n",
        "      self.train_transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=45),\n",
        "                transforms.ToTensor()\n",
        "                ])\n",
        "        \n",
        "      self.test_transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor()])\n",
        "      \n",
        "    def __len__(self):\n",
        "      return len(self.df)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "\n",
        "      row = self.df.loc[idx,:]\n",
        "      pid = row['id']\n",
        "      sub_df = self.df[self.df['id'] == pid]\n",
        "        \n",
        "      try: \n",
        "     \n",
        "        img_id = np.random.choice(len(sub_df)) # randomly choose a patient image inside the fold \n",
        "        image = cv2.imread(str(self.path)  + '/' + self.folder + '/' + sub_df.iloc[img_id,:]['image_rename'])\n",
        "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        img = self.train_transform(image) if self.is_train else self.test_transform(image)\n",
        "         \n",
        "        tab = torch.from_numpy(sub_df.iloc[img_id,:].drop(train_cols_to_drop).values.astype(np.float)).float() # dtype = torch.float32\n",
        "        target = torch.tensor(row['OS'])\n",
        "        return (img,tab), target , torch.tensor(sub_df.iloc[img_id]['id_encoding']) , torch.tensor(sub_df.iloc[img_id]['image_rename_encoding'])\n",
        "        \n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        print(pid, img_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRWfmtmaTgvl"
      },
      "source": [
        "## Collate Function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "HziZdEn_TirM"
      },
      "outputs": [],
      "source": [
        "def collate_fn(b):\n",
        "    xs, ys, pids,img_rename = zip(*b)\n",
        "    imgs, tabs = zip(*xs) # doule tuple \n",
        "    return (torch.stack(imgs).float(),torch.stack(tabs).float()),torch.stack(ys).float() , torch.stack(pids) , torch.stack(img_rename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSRPze0cVpAv"
      },
      "source": [
        "## Generating Splits "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "k148qJu2VrwO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def get_split_idxs(n_folds=5):\n",
        "    kv = KFold(n_splits=n_folds)\n",
        "    splits = []\n",
        "    for i,(train_idx, valid_idx) in enumerate(kv.split(unique_patient_ids)):\n",
        "        splits.append((train_idx, valid_idx))\n",
        "        \n",
        "    return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "pBpu-Ow8Vtvm"
      },
      "outputs": [],
      "source": [
        "splits = get_split_idxs(n_folds=config.FOLDS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ4pjbDFV1lE",
        "outputId": "16e5df4f-8fd3-40eb-c77f-0b560e135974"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "         26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([0, 1, 2, 3, 4, 5, 6, 7, 8])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "         26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([ 9, 10, 11, 12, 13, 14, 15, 16, 17])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([18, 19, 20, 21, 22, 23, 24, 25])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 34, 35, 36, 37, 38, 39, 40, 41]),\n",
              "  array([26, 27, 28, 29, 30, 31, 32, 33])),\n",
              " (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]),\n",
              "  array([34, 35, 36, 37, 38, 39, 40, 41]))]"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo-olt8sQ2Tj"
      },
      "source": [
        "# Training propsed model\n",
        "\n",
        "GOAL:\n",
        "```\n",
        "Image Data --> CNNLayer \n",
        "                    \\\n",
        "                     ---> FCLayer ---> Output\n",
        "                    /\n",
        "Metadata --> FCLayer\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80E89X4BT6Lv"
      },
      "source": [
        "## Loading Supervised Pretrained \n",
        "\n",
        "Original paper: https://arxiv.org/pdf/2011.13971.pdf\n",
        "\n",
        "Repo: https://github.com/ozanciga/self-supervised-histopathology/tree/tenpercent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "IY5FUluLeN6i"
      },
      "outputs": [],
      "source": [
        "RETURN_PREACTIVATION = True  # return features from the model, if false return classification logits\n",
        "NUM_CLASSES = 1  # only used if RETURN_PREACTIVATION = False\n",
        "\n",
        "\n",
        "def load_model_weights(model, weights):\n",
        "\n",
        "    model_dict = model.state_dict()\n",
        "    weights = {k: v for k, v in weights.items() if k in model_dict}\n",
        "    if weights == {}:\n",
        "        print('No weight could be loaded..')\n",
        "    model_dict.update(weights)\n",
        "    model.load_state_dict(model_dict)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = torchvision.models.__dict__['resnet18'](pretrained=False)\n",
        "state = torch.load(TEN_PERCENT_MODEL_PATH, map_location='cuda:0')\n",
        "\n",
        "state_dict = state['state_dict']\n",
        "for key in list(state_dict.keys()):\n",
        "    state_dict[key.replace('model.', '').replace('resnet.', '')] = state_dict.pop(key)\n",
        "\n",
        "model = load_model_weights(model, state_dict)\n",
        "\n",
        "if RETURN_PREACTIVATION:\n",
        "    model.fc = torch.nn.Sequential()\n",
        "else:\n",
        "    model.fc = torch.nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "images = torch.rand((10, 3, 224, 224), device='cuda')\n",
        "\n",
        "out = model(images)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    # Replace the last fully-connected layer\n",
        "    # Parameters of newly constructed modules have requires_grad=True by default\n",
        "    \n",
        "    model.fc = torch.nn.Linear(512, 256,bias = True) \n",
        "    model = model.cuda()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "5_lV19Ecep-y"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "proposed_model = copy.deepcopy(model)\n",
        "\n",
        "count = 1\n",
        "for param in proposed_model.parameters():\n",
        "  count += 1\n",
        "\n",
        "cur = 1\n",
        "for param in proposed_model.parameters():\n",
        "  if (cur > (0.8 * count)): \n",
        "    param.requires_grad = True\n",
        "  cur += 1\n",
        "\n",
        "proposed_model = proposed_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxMZaNLnT_nX"
      },
      "source": [
        "## Training Global Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "lRctuPvUaGKF"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, dl, opt , device, loss_fn):\n",
        "    model.train()\n",
        "    final_loss = []\n",
        "    for X,y,_,_ in dl:\n",
        "        imgs = X[0].to(device)\n",
        "        tabs = X[1].to(device)\n",
        "        y = y.to(device)\n",
        "        outputs = model(imgs, tabs)\n",
        "        loss = loss_fn(outputs.squeeze(), y)\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        final_loss.append(loss.detach().cpu().numpy())\n",
        "        #print('Training Example preds vs targets: ::\\t \\n' , outputs , '\\n' , y)\n",
        "    return np.array(final_loss).mean()\n",
        "    \n",
        "def eval_loop(model, dl, device, loss_fn):\n",
        "    model.eval()\n",
        "    final_outputs = []\n",
        "    final_loss = []\n",
        "    with torch.no_grad():\n",
        "        for X,y,_,_ in dl:\n",
        "            imgs = X[0].to(device)\n",
        "            tabs = X[1].to(device)\n",
        "            y=y.to(device)\n",
        "\n",
        "            outputs = model(imgs, tabs)\n",
        "            loss = loss_fn(outputs.squeeze(), y)\n",
        "\n",
        "            final_outputs.extend(outputs.detach().cpu().numpy().tolist())\n",
        "            final_loss.append(loss.detach().cpu().numpy())\n",
        "\n",
        "    print('validation Example preds vs targets: ::\\t \\n' , outputs , '\\n' , y)\n",
        "    return final_outputs, final_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "aXqjrWURRMrc"
      },
      "outputs": [],
      "source": [
        "class Global_Model(nn.Module): # model to combina both tab and imag \n",
        "    def __init__(self , pretrained_medical_resnet):\n",
        "        super().__init__()\n",
        "        self.conv_model = pretrained_medical_resnet # after freezing some layers and setting regression node as 1 not 4 \n",
        "        self.tab_model = nn.Sequential(nn.Linear(11, 500),\n",
        "                                  nn.BatchNorm1d(500),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2),\n",
        "                                  nn.Linear(500,250),\n",
        "                                  nn.BatchNorm1d(250),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Dropout(p=0.2))\n",
        "                                  \n",
        "        self.output =             nn.Sequential(\n",
        "                                                nn.Linear(250 + 256 ,250),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(250, 125),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(125, 60),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(60, 20),\n",
        "                                                nn.ReLU(),\n",
        "                                                nn.Dropout(p=0.3),\n",
        "                                                nn.Linear(20, 1, bias = True ))\n",
        "    def forward(self, x,tab): # x image , tab is tabular data related \n",
        "        x = self.conv_model(x)\n",
        "        tab_out = self.tab_model(tab)\n",
        "        x = torch.cat([x, tab_out],dim=1)\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "rcHaW7FYaV2l"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "for i in range(config.FOLDS):\n",
        "    models[i] = copy.deepcopy(Global_Model(copy.deepcopy(proposed_model)))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "h5y9erznawDF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "4bd9a6a1-451f-49af-fd15-6362b4f3a617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===================Fold : 0 ================\n",
            "train_idx :  [ 8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31\n",
            " 32 33 34 35 36 37] \n",
            " valid_idx [0 1 2 3 4 5 6 7]\n",
            "=================EPOCHS 1================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-142-b94dbf6b43eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"=================EPOCHS {epoch+1}================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-139-93368ddac3d8>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, dl, opt, device, loss_fn)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-132-2d2fc55f6015>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mimg_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# randomly choose a patient image inside the fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_rename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = []\n",
        "trainhistory = []\n",
        "\n",
        "bestModels = []\n",
        "bestScores = []\n",
        "\n",
        "for i, (train_idx, valid_idx) in enumerate(splits):\n",
        "    bestModel = None\n",
        "    bestHistory = 100\n",
        "\n",
        "    print(f\"===================Fold : {i} ================\")\n",
        "    print(\"train_idx : \" , train_idx , \"\\n valid_idx\" , valid_idx)\n",
        "\n",
        "    train = train_df.loc[train_df['id'].isin(unique_patient_ids[train_idx])].reset_index(drop=True)\n",
        "    valid = train_df.loc[train_df['id'].isin(unique_patient_ids[valid_idx])].reset_index(drop=True)\n",
        "    \n",
        "    train_ds = Dataset(path, train,'Train' ,1)\n",
        "    train_dl = torch.utils.data.DataLoader(dataset=train_ds,batch_size=config.TRAIN_BS,shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "    valid_ds = Dataset(path, valid,'Train' ,0)\n",
        "    valid_dl = torch.utils.data.DataLoader(dataset=valid_ds,batch_size=config.VALID_BS, shuffle=True,collate_fn=collate_fn)\n",
        "\n",
        "    model = models[i]\n",
        "    model.to(config.DEVICE)\n",
        "    lr=1e-3\n",
        "    momentum = 0.9\n",
        "    \n",
        "    num_steps = len(train_dl)\n",
        "    optimizer = Adam(model.parameters(), lr=lr,weight_decay=0.01)\n",
        "\n",
        "    train_losses = []\n",
        "    losses = []\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        print(f\"=================EPOCHS {epoch+1}================\")\n",
        "        train_loss = train_loop(model, train_dl, optimizer, config.DEVICE,config.loss_fn)\n",
        "        metrics = eval_loop(model, valid_dl, config.DEVICE,config.loss_fn)\n",
        "        total_loss = np.array(metrics[1]).mean()\n",
        "\n",
        "        if (total_loss < bestHistory):\n",
        "          print('New best model! Score: ', total_loss)\n",
        "          patienceCounter = 0\n",
        "          bestHistory = total_loss\n",
        "          bestModel = copy.deepcopy(model)\n",
        "        \n",
        "        if (epoch > patienceCounter):\n",
        "          if (total_loss >  bestHistory):\n",
        "            patienceCounter += 1\n",
        "            print('BAD! Patience counter : ', patienceCounter)\n",
        "\n",
        "        \n",
        "        if (patienceCounter >= patience):\n",
        "          print('Early stopping saved')\n",
        "          break\n",
        "        \n",
        "        losses.append(total_loss)\n",
        "        train_losses.append(train_loss)\n",
        "        print('Train Loss:: \\t', train_loss)\n",
        "        print(\"Validation Loss ::\\t\", total_loss)\n",
        "        \n",
        "    model.to('cpu')\n",
        "\n",
        "    history.append(losses)\n",
        "    bestModels.append(bestModel)\n",
        "    bestScores.append(bestHistory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model utils like graphs and saving"
      ],
      "metadata": {
        "id": "6MGLeF18CDE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure(figsize=(6, 8), dpi=80)\n",
        "\n",
        "f, axes = plt.subplots(len(history), 1)\n",
        "f.set_size_inches(12, 20)\n",
        "for i in range(len(history)):\n",
        "  axes[i].plot(history[i])\n",
        "  #axes[i].plot(trainhistory[i])\n",
        "\n",
        "  axes[i].legend(['Validation Loss'])\n",
        "  axes[i].set_title(' Fold ' + str(i))"
      ],
      "metadata": {
        "id": "FxSv8jP5CH-C",
        "outputId": "ab78ecc4-c0eb-426c-c581-09e4fa9ac9b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x640 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x1440 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get best val loss scores per fold\n",
        "for m in history:\n",
        "  print(min(m))"
      ],
      "metadata": {
        "id": "1NK6giFLCgd_"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best models\n",
        "c = 0\n",
        "for m in bestModels:\n",
        "    torch.save(m.state_dict(), OUTPUT_MODEL_PATH + f'/tab_best_fold_{c}.pth')\n",
        "    c += 1"
      ],
      "metadata": {
        "id": "fVQ3kzQVjHaR"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, m in models.items():\n",
        "    torch.save(m.state_dict(), OUTPUT_MODEL_PATH + f'/fold_{k}.pth')"
      ],
      "metadata": {
        "id": "_csLQKqzCNdn"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OriidIi3coKP"
      },
      "source": [
        "# Testing Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "lBtFOYqyDWsV"
      },
      "outputs": [],
      "source": [
        "fold_models_directory = Path(OUTPUT_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold_models_directory.ls()[6:11]"
      ],
      "metadata": {
        "id": "UtknJHZyTQ5E",
        "outputId": "6101fddc-7c05-481f-b8d3-894d47e7779c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/drive/MyDrive/Kaggle/ModelDump/fold_0.pth'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ModelDump/fold_2.pth'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ModelDump/fold_1.pth'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ModelDump/fold_3.pth'),\n",
              " PosixPath('/content/drive/MyDrive/Kaggle/ModelDump/fold_4.pth')]"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "FPiYeptIDTE3"
      },
      "outputs": [],
      "source": [
        "model_device = torch.device('cpu')\n",
        "for i , fold_model_path in enumerate(fold_models_directory.ls()[6:11]) :\n",
        "    models[i].load_state_dict(torch.load(str(fold_model_path) , map_location = model_device), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "ojBhpb88IpEQ"
      },
      "outputs": [],
      "source": [
        "test_df['OS'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "7ny534iiFgn_"
      },
      "outputs": [],
      "source": [
        "test_pred_dict = {}\n",
        "submissionDF = pd.DataFrame()\n",
        "\n",
        "test_ds = Dataset(path, test_df,'Test' ,0)\n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_ds,batch_size=1, shuffle=False,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dic = {k:v for k,v in dict(tuple(test_df[['id' ,'id_encoding']].groupby(['id','id_encoding']))).keys()}\n",
        "decoding_dic = {v:k for k,v in encoding_dic.items()} "
      ],
      "metadata": {
        "id": "_23R0wHvlrZN"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_count_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9).flatten())) # count number of occurence for a cetain patient id in the batch \n",
        "fold_mean_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9,dtype=int).flatten())) # compute mean fold "
      ],
      "metadata": {
        "id": "6BWpmpTQWcKx"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df = pd.DataFrame(columns = fold_mean_dict.keys()) "
      ],
      "metadata": {
        "id": "qVUuYAg_ekqk"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "ydbgwziRtgcb",
        "outputId": "c3e4b0d4-f939-4cb1-8066-edef9d7a8bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================Predictions of fold Model 0================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-182-631648ee3692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mfold_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mtabs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-164-2d2fc55f6015>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mimg_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# randomly choose a patient image inside the fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msub_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image_rename'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Test Set \n",
        "for key , fold_model in models.items() : \n",
        "  print(f\"=================Predictions of fold Model {key}================\")\n",
        "  fold_model.to(config.DEVICE)\n",
        "  fold_model.eval()\n",
        "  with torch.no_grad():\n",
        "      for X,y,pid,_ in test_dl:\n",
        "          imgs = X[0].to(config.DEVICE)\n",
        "          tabs = X[1].to(config.DEVICE)\n",
        "          y=y.to(config.DEVICE)\n",
        "          patient_id = pid.detach().cpu().numpy()[0]\n",
        "          outputs = fold_model(imgs, tabs).detach().cpu().numpy()[0]\n",
        "\n",
        "          fold_count_dict[decoding_dic[patient_id]]+=1\n",
        "          fold_mean_dict[decoding_dic[patient_id]] += outputs\n",
        "           \n",
        "      fold_mean_dict = {k : v / fold_count_dict[k]  for k,v in fold_mean_dict.items()}\n",
        "      print (\"Fold count dict : \" , fold_count_dict)\n",
        "      print (\"Fold mean dict after dividing : \" , fold_mean_dict)\n",
        "    \n",
        "      final_submit_df.loc[len(final_submit_df)] = [v[0] for v in fold_mean_dict.values()]\n",
        "      fold_mean_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9,dtype=int).flatten())) # reset for next fold \n",
        "      fold_count_dict = dict(zip(test_df['id'].unique().flatten(), np.zeros(9).flatten()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df"
      ],
      "metadata": {
        "id": "Qgt0aSPdg539"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df.mean(axis=0)"
      ],
      "metadata": {
        "id": "AdB_4gMyiMfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_submit_df.std(axis=0)"
      ],
      "metadata": {
        "id": "7mC5Ka4xiPUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissionDF = pd.DataFrame(final_submit_df.mean(axis=0)).reset_index().rename({'index' : 'id' , 0 : 'prediction' } , axis=1 )"
      ],
      "metadata": {
        "id": "DjDshyx6ieVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submissionDF"
      ],
      "metadata": {
        "id": "LcLGHgsEjSVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pabXigZzHkw3"
      },
      "outputs": [],
      "source": [
        "submissionDF.to_csv(\"submission_V1.csv\" , index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Run_Model-ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}